{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Test Set Generation using RAGAS\n",
    "This notebook demonstrates how to generate a synthetic test set of questions that can be used to evaluate a RAG pipeline using the RAGAS library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from ragas.run_config import RunConfig\n",
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()  # apply the event loop async fix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create all the necessary objects used to access the local LLM, embeddings and create a generator object that will be used to create the test set. We then define a distribution for the types of questions we want to be generated in our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"mistral-nemo\", num_ctx=16384)\n",
    "embeddings = OllamaEmbeddings(model=\"mistral-nemo\", num_ctx=16384)\n",
    "gen = TestsetGenerator.from_langchain(\n",
    "    llm, llm, embeddings, run_config=RunConfig(max_workers=1, max_retries=1)\n",
    ")\n",
    "dist = {simple: 0.6, multi_context: 0.2, reasoning: 0.2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load some text/documents that will be used to create the synthetic test set. These can be loaded in anyway you see fit but should be of type `langchain.docstore.document.Document`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []  # load a set of langchain documents to base the synthetic test set generation on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we generate the test set. Here we are only generating `5` test questions for speed, but generate as many as you feel you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = gen.generate_with_langchain_docs(docs, 5, dist, is_async=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally convert the test set to a pandas data frame and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = testset.to_pandas()\n",
    "df.to_csv(\"data/synthetic-datasets/test-set.csv\", index=False)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
